{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (12, 6)\n",
    "mpl.rcParams['axes.grid'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>product_rk</th>\n      <th>store_location_rk</th>\n      <th>period_start_dt</th>\n      <th>demand</th>\n      <th>PROMO1_FLAG</th>\n      <th>PROMO2_FLAG</th>\n      <th>PRICE_REGULAR</th>\n      <th>PRICE_AFTER_DISC</th>\n      <th>NUM_CONSULTANT</th>\n      <th>AUTORIZATION_FLAG</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>40369</td>\n      <td>309</td>\n      <td>2016-12-19</td>\n      <td>29.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>40370</td>\n      <td>309</td>\n      <td>2016-12-19</td>\n      <td>64.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>40372</td>\n      <td>309</td>\n      <td>2016-12-19</td>\n      <td>32.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>40373</td>\n      <td>309</td>\n      <td>2016-12-19</td>\n      <td>10.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>46272</td>\n      <td>309</td>\n      <td>2016-12-19</td>\n      <td>15.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>35339</th>\n      <td>35537</td>\n      <td>40370</td>\n      <td>1380</td>\n      <td>2019-12-30</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1000.00</td>\n      <td>1000.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>35340</th>\n      <td>35538</td>\n      <td>40372</td>\n      <td>1380</td>\n      <td>2019-12-30</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2000.00</td>\n      <td>2000.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>35341</th>\n      <td>35539</td>\n      <td>40373</td>\n      <td>1380</td>\n      <td>2019-12-30</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3000.00</td>\n      <td>3000.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>35342</th>\n      <td>35540</td>\n      <td>46272</td>\n      <td>1380</td>\n      <td>2019-12-30</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>284.29</td>\n      <td>199.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>35343</th>\n      <td>35541</td>\n      <td>96212</td>\n      <td>1380</td>\n      <td>2019-12-30</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>141.43</td>\n      <td>99.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>35344 rows × 11 columns</p>\n</div>",
      "text/plain": "       Unnamed: 0  product_rk  store_location_rk period_start_dt  demand  \\\n0               0       40369                309      2016-12-19    29.0   \n1               1       40370                309      2016-12-19    64.0   \n2               2       40372                309      2016-12-19    32.0   \n3               3       40373                309      2016-12-19    10.0   \n4               4       46272                309      2016-12-19    15.0   \n...           ...         ...                ...             ...     ...   \n35339       35537       40370               1380      2019-12-30     NaN   \n35340       35538       40372               1380      2019-12-30     NaN   \n35341       35539       40373               1380      2019-12-30     NaN   \n35342       35540       46272               1380      2019-12-30     NaN   \n35343       35541       96212               1380      2019-12-30     NaN   \n\n       PROMO1_FLAG  PROMO2_FLAG  PRICE_REGULAR  PRICE_AFTER_DISC  \\\n0              NaN          NaN            NaN               NaN   \n1              NaN          NaN            NaN               NaN   \n2              NaN          NaN            NaN               NaN   \n3              NaN          NaN            NaN               NaN   \n4              NaN          NaN            NaN               NaN   \n...            ...          ...            ...               ...   \n35339          0.0          0.0        1000.00            1000.0   \n35340          0.0          0.0        2000.00            2000.0   \n35341          0.0          0.0        3000.00            3000.0   \n35342          1.0          0.0         284.29             199.0   \n35343          1.0          0.0         141.43              99.0   \n\n       NUM_CONSULTANT  AUTORIZATION_FLAG  \n0                 NaN                NaN  \n1                 NaN                NaN  \n2                 NaN                NaN  \n3                 NaN                NaN  \n4                 NaN                NaN  \n...               ...                ...  \n35339             0.0                1.0  \n35340             0.0                1.0  \n35341             0.0                1.0  \n35342             0.0                1.0  \n35343             0.0                1.0  \n\n[35344 rows x 11 columns]"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../demand-forecasting-in-retail/train.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df.period_start_dt, format='%Y-%m-%d')\n",
    "# log price\n",
    "# df['PRICE_REGULAR'] = np.log(df.PRICE_REGULAR)\n",
    "# date to 10^8 sec\n",
    "df.date = df.date.astype(np.int64)/3600/24\n",
    "df.date = df.date.astype(np.int64)/10**9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array(['2016-12-19', '2016-12-26', '2017-01-02', '2017-01-09',\n       '2017-01-16', '2017-01-23', '2017-01-30', '2017-02-06',\n       '2017-02-13', '2017-02-20', '2017-02-27', '2017-03-06',\n       '2017-03-13', '2017-03-20', '2017-03-27', '2017-04-03',\n       '2017-04-10', '2017-04-17', '2017-04-24', '2017-05-01',\n       '2017-05-08', '2017-05-15', '2017-05-22', '2017-05-29',\n       '2017-06-05', '2017-06-12', '2017-06-19', '2017-06-26',\n       '2017-07-03', '2017-07-10', '2017-07-17', '2017-07-24',\n       '2017-07-31', '2017-08-07', '2017-08-14', '2017-08-21',\n       '2017-08-28', '2017-09-04', '2017-09-11', '2017-09-18',\n       '2017-09-25', '2017-10-02', '2017-10-09', '2017-10-16',\n       '2017-10-23', '2017-10-30', '2017-11-06', '2017-11-13',\n       '2017-11-20', '2017-11-27', '2017-12-04', '2017-12-11',\n       '2017-12-18', '2017-12-25', '2018-01-01', '2018-01-08',\n       '2018-01-15', '2018-01-22', '2018-01-29', '2018-02-05',\n       '2018-02-12', '2018-02-19', '2018-02-26', '2018-03-05',\n       '2018-03-12', '2018-03-19', '2018-03-26', '2018-04-02',\n       '2018-04-09', '2018-04-16', '2018-04-23', '2018-04-30',\n       '2018-05-07', '2018-05-14', '2018-05-21', '2018-05-28',\n       '2018-06-04', '2018-06-11', '2018-06-18', '2018-06-25',\n       '2018-07-02', '2018-07-09', '2018-07-16', '2018-07-23',\n       '2018-07-30', '2018-08-06', '2018-08-13', '2018-08-20',\n       '2018-08-27', '2018-09-03', '2018-09-10', '2018-09-17',\n       '2018-09-24', '2018-10-01', '2018-10-08', '2018-10-15',\n       '2018-10-22', '2018-10-29', '2018-11-05', '2018-11-12',\n       '2018-11-19', '2018-11-26', '2018-12-03', '2018-12-10',\n       '2018-12-17', '2018-12-24', '2018-12-31', '2019-01-07',\n       '2019-01-14', '2019-01-21', '2019-01-28', '2019-02-04',\n       '2019-02-11', '2019-02-18', '2019-02-25', '2019-03-04',\n       '2019-03-11', '2019-03-18', '2019-03-25', '2019-04-01',\n       '2019-04-08', '2019-04-15', '2019-04-22', '2019-04-29',\n       '2019-05-06', '2019-05-13', '2019-05-20', '2019-05-27',\n       '2019-06-03', '2019-06-10', '2019-06-17', '2019-06-24',\n       '2019-07-01', '2019-07-08', '2019-07-15', '2019-07-22',\n       '2019-07-29', '2019-08-05', '2019-08-12', '2019-08-19',\n       '2019-08-26', '2019-09-02', '2019-09-09', '2019-09-16',\n       '2019-09-23', '2019-09-30', '2019-10-07', '2019-10-14',\n       '2019-10-21', '2019-10-28', '2019-11-04', '2019-11-11',\n       '2019-11-18', '2019-11-25', '2019-12-02', '2019-12-09',\n       '2019-12-16', '2019-12-23', '2019-12-30'], dtype=object)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "period_starts = df.period_start_dt.unique()\n",
    "period_starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "159"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(period_starts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = df[ (df['period_start_dt'] == '2016-12-19') | \n",
    "            (df['period_start_dt'] == '2017-12-19') | \n",
    "            (df['period_start_dt'] == '2018-12-19') |\n",
    "            (df['period_start_dt'] == '2019') |\n",
    "\n",
    "            (df['period_start_dt'] == '2016-12-26') |\n",
    "            (df['period_start_dt'] == '2017-12-26') |\n",
    "            (df['period_start_dt'] == '2018-12-26') |\n",
    "            (df['period_start_dt'] == '2019-12-26') |\n",
    "\n",
    "            (df['period_start_dt'] == '2016-03-06') |\n",
    "            (df['period_start_dt'] == '2017-03-06') |\n",
    "            (df['period_start_dt'] == '2018-03-06') |\n",
    "            (df['period_start_dt'] == '2019-03-06') |\n",
    "\n",
    "            (df['period_start_dt'] == '2016-02-20') |\n",
    "            (df['period_start_dt'] == '2017-02-20') |\n",
    "            (df['period_start_dt'] == '2018-02-20') |\n",
    "            (df['period_start_dt'] == '2019-02-20')  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['holiday_flag'] = np.where(df.index.isin(dummy.index), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>product_rk</th>\n      <th>store_location_rk</th>\n      <th>period_start_dt</th>\n      <th>demand</th>\n      <th>PROMO1_FLAG</th>\n      <th>PROMO2_FLAG</th>\n      <th>PRICE_REGULAR</th>\n      <th>PRICE_AFTER_DISC</th>\n      <th>NUM_CONSULTANT</th>\n      <th>AUTORIZATION_FLAG</th>\n      <th>date</th>\n      <th>holiday_flag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>40369</td>\n      <td>309</td>\n      <td>2016-12-19</td>\n      <td>29.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>17154.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>40370</td>\n      <td>309</td>\n      <td>2016-12-19</td>\n      <td>64.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>17154.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>40372</td>\n      <td>309</td>\n      <td>2016-12-19</td>\n      <td>32.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>17154.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>40373</td>\n      <td>309</td>\n      <td>2016-12-19</td>\n      <td>10.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>17154.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>46272</td>\n      <td>309</td>\n      <td>2016-12-19</td>\n      <td>15.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>17154.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>32121</th>\n      <td>32296</td>\n      <td>40369</td>\n      <td>1326</td>\n      <td>2017-03-06</td>\n      <td>416.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>500.0</td>\n      <td>500.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>17231.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>32122</th>\n      <td>32297</td>\n      <td>40370</td>\n      <td>1326</td>\n      <td>2017-03-06</td>\n      <td>428.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1000.0</td>\n      <td>1000.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>17231.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>32123</th>\n      <td>32298</td>\n      <td>40372</td>\n      <td>1326</td>\n      <td>2017-03-06</td>\n      <td>129.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2000.0</td>\n      <td>2000.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>17231.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>32124</th>\n      <td>32299</td>\n      <td>40373</td>\n      <td>1326</td>\n      <td>2017-03-06</td>\n      <td>96.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3000.0</td>\n      <td>3000.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>17231.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>32125</th>\n      <td>32300</td>\n      <td>46272</td>\n      <td>1326</td>\n      <td>2017-03-06</td>\n      <td>18.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>191.0</td>\n      <td>191.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>17231.0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>695 rows × 13 columns</p>\n</div>",
      "text/plain": "       Unnamed: 0  product_rk  store_location_rk period_start_dt  demand  \\\n0               0       40369                309      2016-12-19    29.0   \n1               1       40370                309      2016-12-19    64.0   \n2               2       40372                309      2016-12-19    32.0   \n3               3       40373                309      2016-12-19    10.0   \n4               4       46272                309      2016-12-19    15.0   \n...           ...         ...                ...             ...     ...   \n32121       32296       40369               1326      2017-03-06   416.0   \n32122       32297       40370               1326      2017-03-06   428.0   \n32123       32298       40372               1326      2017-03-06   129.0   \n32124       32299       40373               1326      2017-03-06    96.0   \n32125       32300       46272               1326      2017-03-06    18.0   \n\n       PROMO1_FLAG  PROMO2_FLAG  PRICE_REGULAR  PRICE_AFTER_DISC  \\\n0              NaN          NaN            NaN               NaN   \n1              NaN          NaN            NaN               NaN   \n2              NaN          NaN            NaN               NaN   \n3              NaN          NaN            NaN               NaN   \n4              NaN          NaN            NaN               NaN   \n...            ...          ...            ...               ...   \n32121          0.0          0.0          500.0             500.0   \n32122          0.0          0.0         1000.0            1000.0   \n32123          0.0          0.0         2000.0            2000.0   \n32124          0.0          0.0         3000.0            3000.0   \n32125          0.0          0.0          191.0             191.0   \n\n       NUM_CONSULTANT  AUTORIZATION_FLAG     date  holiday_flag  \n0                 NaN                NaN  17154.0             1  \n1                 NaN                NaN  17154.0             1  \n2                 NaN                NaN  17154.0             1  \n3                 NaN                NaN  17154.0             1  \n4                 NaN                NaN  17154.0             1  \n...               ...                ...      ...           ...  \n32121             0.0                1.0  17231.0             1  \n32122             0.0                1.0  17231.0             1  \n32123             0.0                1.0  17231.0             1  \n32124             0.0                1.0  17231.0             1  \n32125             0.0                1.0  17231.0             1  \n\n[695 rows x 13 columns]"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.index.isin(dummy.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>product_rk</th>\n      <th>store_location_rk</th>\n      <th>period_start_dt</th>\n      <th>demand</th>\n      <th>PROMO1_FLAG</th>\n      <th>PROMO2_FLAG</th>\n      <th>PRICE_REGULAR</th>\n      <th>PRICE_AFTER_DISC</th>\n      <th>NUM_CONSULTANT</th>\n      <th>AUTORIZATION_FLAG</th>\n      <th>date</th>\n      <th>holiday_flag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>40369</td>\n      <td>309</td>\n      <td>2016-12-19</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>17154.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>40370</td>\n      <td>309</td>\n      <td>2016-12-19</td>\n      <td>64.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>17154.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>40372</td>\n      <td>309</td>\n      <td>2016-12-19</td>\n      <td>32.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>17154.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>40373</td>\n      <td>309</td>\n      <td>2016-12-19</td>\n      <td>10.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>17154.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>46272</td>\n      <td>309</td>\n      <td>2016-12-19</td>\n      <td>15.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>17154.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>35339</th>\n      <td>35537</td>\n      <td>40370</td>\n      <td>1380</td>\n      <td>2019-12-30</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1000.00</td>\n      <td>1000.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>18260.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>35340</th>\n      <td>35538</td>\n      <td>40372</td>\n      <td>1380</td>\n      <td>2019-12-30</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2000.00</td>\n      <td>2000.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>18260.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>35341</th>\n      <td>35539</td>\n      <td>40373</td>\n      <td>1380</td>\n      <td>2019-12-30</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3000.00</td>\n      <td>3000.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>18260.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>35342</th>\n      <td>35540</td>\n      <td>46272</td>\n      <td>1380</td>\n      <td>2019-12-30</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>284.29</td>\n      <td>199.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>18260.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>35343</th>\n      <td>35541</td>\n      <td>96212</td>\n      <td>1380</td>\n      <td>2019-12-30</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>141.43</td>\n      <td>99.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>18260.0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>35344 rows × 13 columns</p>\n</div>",
      "text/plain": "       Unnamed: 0  product_rk  store_location_rk period_start_dt  demand  \\\n0               0       40369                309      2016-12-19    29.0   \n1               1       40370                309      2016-12-19    64.0   \n2               2       40372                309      2016-12-19    32.0   \n3               3       40373                309      2016-12-19    10.0   \n4               4       46272                309      2016-12-19    15.0   \n...           ...         ...                ...             ...     ...   \n35339       35537       40370               1380      2019-12-30     0.0   \n35340       35538       40372               1380      2019-12-30     0.0   \n35341       35539       40373               1380      2019-12-30     0.0   \n35342       35540       46272               1380      2019-12-30     0.0   \n35343       35541       96212               1380      2019-12-30     0.0   \n\n       PROMO1_FLAG  PROMO2_FLAG  PRICE_REGULAR  PRICE_AFTER_DISC  \\\n0              0.0          0.0           0.00               0.0   \n1              0.0          0.0           0.00               0.0   \n2              0.0          0.0           0.00               0.0   \n3              0.0          0.0           0.00               0.0   \n4              0.0          0.0           0.00               0.0   \n...            ...          ...            ...               ...   \n35339          0.0          0.0        1000.00            1000.0   \n35340          0.0          0.0        2000.00            2000.0   \n35341          0.0          0.0        3000.00            3000.0   \n35342          1.0          0.0         284.29             199.0   \n35343          1.0          0.0         141.43              99.0   \n\n       NUM_CONSULTANT  AUTORIZATION_FLAG     date  holiday_flag  \n0                 0.0                0.0  17154.0             1  \n1                 0.0                0.0  17154.0             1  \n2                 0.0                0.0  17154.0             1  \n3                 0.0                0.0  17154.0             1  \n4                 0.0                0.0  17154.0             1  \n...               ...                ...      ...           ...  \n35339             0.0                1.0  18260.0             0  \n35340             0.0                1.0  18260.0             0  \n35341             0.0                1.0  18260.0             0  \n35342             0.0                1.0  18260.0             0  \n35343             0.0                1.0  18260.0             0  \n\n[35344 rows x 13 columns]"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "jan2020 = df[df['period_start_dt'].isin(['2019-12-30'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(240, 13)"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jan2020.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "jan2020_df = jan2020[['period_start_dt', 'demand', 'date', 'product_rk', 'store_location_rk']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('period_start_dt', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_st_ids = df.store_location_rk.unique()\n",
    "uni_sku_ids = df.product_rk.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(df, store_ids, sku_ids, univar=False):\n",
    "    batches = []\n",
    "    for sku_id in sku_ids:\n",
    "        for store_id in store_ids:\n",
    "            if univar:\n",
    "                batch = df[(df['store_location_rk'] == store_id) & (df['product_rk'] == sku_id)]['demand']\n",
    "            else:\n",
    "                batch = df[(df['store_location_rk'] == store_id) & (df['product_rk'] == sku_id)]\n",
    "            batches.append(batch.values)\n",
    "    return batches\n",
    "\n",
    "\n",
    "def split_dataset_other(df, sku_ids, demand_bool=False):\n",
    "    batches = []\n",
    "    for sku_id in sku_ids:\n",
    "        batch = df[df['product_rk'] == sku_id]['demand']\n",
    "        batches.append(batch.values)\n",
    "    return np.array(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitted_df = split_dataset(df, uni_st_ids, uni_sku_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6074,)\n",
      "(6074,)\n",
      "(6073,)\n",
      "(6074,)\n",
      "(6068,)\n",
      "(4981,)\n"
     ]
    }
   ],
   "source": [
    "for sh in split_dataset_other(df, uni_sku_ids):\n",
    "    print(sh.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "246"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(splitted_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "246"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(uni_sku_ids)*len(uni_st_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = []\n",
    "for idf in splitted_df:\n",
    "    if idf.shape[0] == 159:\n",
    "        tmp.append(idf)\n",
    "splitted_df=tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_sku_store = []\n",
    "for idf in splitted_df:\n",
    "    norm_sku_store.append(str(idf[0, 0])+str(idf[0, 1]))\n",
    "# norm_sku_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "170"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(norm_sku_store)\n",
    "# norm_sku_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>period_start_dt</th>\n      <th>demand</th>\n      <th>date</th>\n      <th>product_rk</th>\n      <th>store_location_rk</th>\n      <th>code</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>932</th>\n      <td>2019-12-30</td>\n      <td>0.0</td>\n      <td>18260.0</td>\n      <td>40369</td>\n      <td>317</td>\n      <td>40369317</td>\n    </tr>\n    <tr>\n      <th>933</th>\n      <td>2019-12-30</td>\n      <td>0.0</td>\n      <td>18260.0</td>\n      <td>40370</td>\n      <td>317</td>\n      <td>40370317</td>\n    </tr>\n    <tr>\n      <th>934</th>\n      <td>2019-12-30</td>\n      <td>0.0</td>\n      <td>18260.0</td>\n      <td>40372</td>\n      <td>317</td>\n      <td>40372317</td>\n    </tr>\n    <tr>\n      <th>935</th>\n      <td>2019-12-30</td>\n      <td>0.0</td>\n      <td>18260.0</td>\n      <td>40373</td>\n      <td>317</td>\n      <td>40373317</td>\n    </tr>\n    <tr>\n      <th>936</th>\n      <td>2019-12-30</td>\n      <td>0.0</td>\n      <td>18260.0</td>\n      <td>46272</td>\n      <td>317</td>\n      <td>46272317</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>35339</th>\n      <td>2019-12-30</td>\n      <td>0.0</td>\n      <td>18260.0</td>\n      <td>40370</td>\n      <td>1380</td>\n      <td>403701380</td>\n    </tr>\n    <tr>\n      <th>35340</th>\n      <td>2019-12-30</td>\n      <td>0.0</td>\n      <td>18260.0</td>\n      <td>40372</td>\n      <td>1380</td>\n      <td>403721380</td>\n    </tr>\n    <tr>\n      <th>35341</th>\n      <td>2019-12-30</td>\n      <td>0.0</td>\n      <td>18260.0</td>\n      <td>40373</td>\n      <td>1380</td>\n      <td>403731380</td>\n    </tr>\n    <tr>\n      <th>35342</th>\n      <td>2019-12-30</td>\n      <td>0.0</td>\n      <td>18260.0</td>\n      <td>46272</td>\n      <td>1380</td>\n      <td>462721380</td>\n    </tr>\n    <tr>\n      <th>35343</th>\n      <td>2019-12-30</td>\n      <td>0.0</td>\n      <td>18260.0</td>\n      <td>96212</td>\n      <td>1380</td>\n      <td>962121380</td>\n    </tr>\n  </tbody>\n</table>\n<p>240 rows × 6 columns</p>\n</div>",
      "text/plain": "      period_start_dt  demand     date  product_rk  store_location_rk  \\\n932        2019-12-30     0.0  18260.0       40369                317   \n933        2019-12-30     0.0  18260.0       40370                317   \n934        2019-12-30     0.0  18260.0       40372                317   \n935        2019-12-30     0.0  18260.0       40373                317   \n936        2019-12-30     0.0  18260.0       46272                317   \n...               ...     ...      ...         ...                ...   \n35339      2019-12-30     0.0  18260.0       40370               1380   \n35340      2019-12-30     0.0  18260.0       40372               1380   \n35341      2019-12-30     0.0  18260.0       40373               1380   \n35342      2019-12-30     0.0  18260.0       46272               1380   \n35343      2019-12-30     0.0  18260.0       96212               1380   \n\n            code  \n932     40369317  \n933     40370317  \n934     40372317  \n935     40373317  \n936     46272317  \n...          ...  \n35339  403701380  \n35340  403721380  \n35341  403731380  \n35342  462721380  \n35343  962121380  \n\n[240 rows x 6 columns]"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jan2020_df['code'] = jan2020_df['product_rk'].astype(str) + jan2020_df['store_location_rk'].astype(str)\n",
    "jan2020_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "jan_actual_df = jan2020_df[jan2020_df['code'].isin(norm_sku_store)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WARNING:deprecated!\n",
    "def create_one_hot(df, col_name):\n",
    "    uni_cols = df[col_name].unique()\n",
    "    df = pd.merge(df, pd.get_dummies(df[col_name], prefix=col_name), left_index=True, right_index=True)\n",
    "    return df.drop(columns=col_name)\n",
    "\n",
    "# df = create_one_hot(df, 'Store_id')\n",
    "# df = create_one_hot(df, 'SKU_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ds(dataset, target_index=2, history_size=5, target_size=5, start_index=0, end_index=None):\n",
    "  data = []\n",
    "  labels = []\n",
    "\n",
    "  start_index = start_index + history_size\n",
    "  if end_index is None:\n",
    "    end_index = len(dataset) - target_size\n",
    "\n",
    "  for i in range(start_index, end_index):\n",
    "    indices = range(i-history_size, i)\n",
    "    data.append(dataset[indices])\n",
    "    # Reshape data from (history_size,) to (history_size, 1)\n",
    "    # data.append(np.reshape(dataset[indices], (history_size, 1)))\n",
    "    labels.append(dataset[i: i+target_size, target_index])\n",
    "  return np.array(data), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = make_ds(splitted_df[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(149, 5, 12)"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(149, 5)"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single window of past history\n",
      "[[1.5000000e+01 4.0369000e+04 3.1700000e+02 5.0000000e+01 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  1.7154000e+04 1.0000000e+00]\n",
      " [2.0000000e+01 4.0369000e+04 3.1700000e+02 6.5000000e+01 1.0000000e+00\n",
      "  0.0000000e+00 5.0000000e+02 5.0000000e+02 0.0000000e+00 1.0000000e+00\n",
      "  1.7161000e+04 1.0000000e+00]\n",
      " [2.5000000e+01 4.0369000e+04 3.1700000e+02 4.1251366e+01 1.0000000e+00\n",
      "  0.0000000e+00 5.0000000e+02 5.0000000e+02 0.0000000e+00 1.0000000e+00\n",
      "  1.7168000e+04 0.0000000e+00]\n",
      " [3.0000000e+01 4.0369000e+04 3.1700000e+02 1.3000000e+01 0.0000000e+00\n",
      "  0.0000000e+00 5.0000000e+02 5.0000000e+02 0.0000000e+00 1.0000000e+00\n",
      "  1.7175000e+04 0.0000000e+00]\n",
      " [3.5000000e+01 4.0369000e+04 3.1700000e+02 1.1000000e+01 0.0000000e+00\n",
      "  0.0000000e+00 5.0000000e+02 5.0000000e+02 0.0000000e+00 1.0000000e+00\n",
      "  1.7182000e+04 0.0000000e+00]]\n",
      "\n",
      " Target demands to predict\n",
      "[317. 317. 317. 317. 317.]\n"
     ]
    }
   ],
   "source": [
    "print ('Single window of past history')\n",
    "print (x[0])\n",
    "print ('\\n Target demands to predict')\n",
    "print (y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_time_steps(length):\n",
    "  return list(range(-length, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_step_plot(history, true_future, prediction):\n",
    "  plt.figure(figsize=(12, 6))\n",
    "  num_in = create_time_steps(len(history))\n",
    "  num_out = len(true_future)\n",
    "\n",
    "  plt.plot(num_in, np.array(history[:, 1]), label='History')\n",
    "  plt.plot(np.arange(num_out)/STEP, np.array(true_future), 'bo',\n",
    "           label='True Future')\n",
    "  if prediction.any():\n",
    "    plt.plot(np.arange(num_out)/STEP, np.array(prediction), 'ro',\n",
    "             label='Predicted Future')\n",
    "  plt.legend(loc='upper left')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_plot(history, true_vals, preds=None):\n",
    "    plt.figure(figsize=(24, 12))\n",
    "    plt.xlim((0, len(history) + len(true_vals)))\n",
    "\n",
    "    plt.plot(range(len(history)), history, label='History')\n",
    "    plt.plot(range(len(history), len(history) + len(true_vals)), true_vals,  '.-', label='True')\n",
    "    plt.plot(range(len(history), len(history) + len(true_vals)), preds, 'ro', label='Pred')\n",
    "    # plt.xticks(labels=df.period_start_dt.unique()[:143])\n",
    "\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline(history):\n",
    "  return np.mean(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = make_ds(splitted_df[0], target_size=12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = []\n",
    "for df in splitted_df:\n",
    "    if df.shape[0] == 159:\n",
    "        new_df.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.LSTM(120, input_shape=x[0].shape[-2:], return_sequences=True),\n",
    "    tf.keras.layers.LSTM(120, input_shape=x[0].shape[-2:]),\n",
    "    tf.keras.layers.Dense(100),\n",
    "    tf.keras.layers.ReLU(),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(12),\n",
    "    tf.keras.layers.Dense(20),\n",
    "    tf.keras.layers.Dense(5)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(df1):\n",
    "    hist = []\n",
    "    for df in df1:\n",
    "        x1, y1 = make_ds(df, target_size=1)\n",
    "        hist.append(model.train_on_batch(x1, y1))\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import  plot_model\n",
    "plot_model(model, to_file='model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnknownError",
     "evalue": "   Fail to find the dnn implementation.\n\t [[{{node CudnnRNN}}]]\n\t [[sequential/lstm/PartitionedCall]] [Op:__inference_train_function_5123]\n\nFunction call stack:\ntrain_function -> train_function -> train_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-fa68dc28d809>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-57-753dbf32a722>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(df1)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_ds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[1;32m   1693\u001b[0m                                                     class_weight)\n\u001b[1;32m   1694\u001b[0m       \u001b[0mtrain_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnknownError\u001b[0m:    Fail to find the dnn implementation.\n\t [[{{node CudnnRNN}}]]\n\t [[sequential/lstm/PartitionedCall]] [Op:__inference_train_function_5123]\n\nFunction call stack:\ntrain_function -> train_function -> train_function\n"
     ]
    }
   ],
   "source": [
    "hist = train(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:TFDS datasets with text encoding are deprecated and will be removed in a future version. Instead, you should use the plain text version and tokenize the text using `tensorflow_text` (See: https://www.tensorflow.org/tutorials/tensorflow_text/intro#tfdata_example)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset 80.23 MiB (download: 80.23 MiB, generated: Unknown size, total: 80.23 MiB) to /home/klechshev/tensorflow_datasets/imdb_reviews/subwords8k/1.0.0...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fb4ec2c1bce4c7f9c6297074f97cf3c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25d755babd144ac299ee05bdc4bc5b7d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4c2d29bf19d4a3aba77e0b176114fb5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2461ecd961d462d807fd56ff4bc6e9a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a635255ddaa4841a0aa1dbfa7cf1f29"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abdc6a44f3ac468fa22527a156b91964"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4e147b67d93497ba2a90d3b2b434a02"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4921ed2589245f593494349889ca7e7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-cf88cc62904d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m dataset, info = tfds.load('imdb_reviews/subwords8k', with_info=True,\n\u001b[0;32m----> 8\u001b[0;31m                           as_supervised=True)\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_datasets/core/load.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, split, data_dir, batch_size, shuffle_files, download, as_supervised, decoders, read_config, with_info, builder_kwargs, download_and_prepare_kwargs, as_dataset_kwargs, try_gcs)\u001b[0m\n\u001b[1;32m    326\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m     \u001b[0mdownload_and_prepare_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload_and_prepare_kwargs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m     \u001b[0mdbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_and_prepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdownload_and_prepare_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mas_dataset_kwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_datasets/core/dataset_builder.py\u001b[0m in \u001b[0;36mdownload_and_prepare\u001b[0;34m(self, download_dir, download_config)\u001b[0m\n\u001b[1;32m    444\u001b[0m             self._download_and_prepare(\n\u001b[1;32m    445\u001b[0m                 \u001b[0mdl_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdl_manager\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m                 \u001b[0mdownload_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m             )\n\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_datasets/core/dataset_builder.py\u001b[0m in \u001b[0;36m_download_and_prepare\u001b[0;34m(self, dl_manager, download_config)\u001b[0m\n\u001b[1;32m   1179\u001b[0m               \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Generating splits...\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m               \u001b[0munit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\" splits\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m               \u001b[0mleave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m           )\n\u001b[1;32m   1183\u001b[0m       ]\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_datasets/core/dataset_builder.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1174\u001b[0m               \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_path\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34mf\"{self.name}-{split_name}.{path_suffix}\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m           )\n\u001b[0;32m-> 1176\u001b[0;31m           \u001b[0;32mfor\u001b[0m \u001b[0msplit_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1177\u001b[0m           in utils.tqdm(\n\u001b[1;32m   1178\u001b[0m               \u001b[0msplit_generators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_datasets/core/split_builder.py\u001b[0m in \u001b[0;36msubmit_split_generation\u001b[0;34m(self, split_name, generator, path)\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;31m# `_build_from_xyz` method.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_from_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbuild_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Otherwise, beam required\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m       unknown_generator_type = TypeError(\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_datasets/core/split_builder.py\u001b[0m in \u001b[0;36m_build_from_generator\u001b[0;34m(self, split_name, generator, path)\u001b[0m\n\u001b[1;32m    360\u001b[0m     ):\n\u001b[1;32m    361\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0mexample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'Failed to encode example:\\n{example}\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_datasets/core/features/features_dict.py\u001b[0m in \u001b[0;36mencode_example\u001b[0;34m(self, example_dict)\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0;32min\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzip_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feature_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m     }\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_datasets/core/features/features_dict.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    192\u001b[0m     return {\n\u001b[1;32m    193\u001b[0m         \u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzip_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feature_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     }\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_datasets/core/features/text_feature.py\u001b[0m in \u001b[0;36mencode_example\u001b[0;34m(self, example_data)\u001b[0m\n\u001b[1;32m    111\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mencode_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m       \u001b[0mexample_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mText\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_datasets/core/deprecated/text/subword_text_encoder.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, s)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_prepare_tokens_for_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow_datasets/core/deprecated/text/subword_text_encoder.py\u001b[0m in \u001b[0;36m_prepare_tokens_for_encode\u001b[0;34m(tokens)\u001b[0m\n\u001b[1;32m    480\u001b[0m     \u001b[0;31m# If the user-supplied string contains the underscore replacement string,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# break it into 2 tokens and encode those separately.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_UNDERSCORE_REPLACEMENT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m       \u001b[0mt1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_UNDERSCORE_REPLACEMENT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_UNDERSCORE_REPLACEMENT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m       \u001b[0mt1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_prepare_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import os\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "dataset, info = tfds.load('imdb_reviews/subwords8k', with_info=True,\n",
    "                          as_supervised=True)\n",
    "train_dataset, test_dataset = dataset['train'], dataset['test']\n",
    "\n",
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE)\n",
    "train_dataset = train_dataset.padded_batch(BATCH_SIZE, train_dataset.output_shapes)\n",
    "\n",
    "test_dataset = test_dataset.padded_batch(BATCH_SIZE, test_dataset.output_shapes)\n",
    "encoder = info.features['text'].encoder\n",
    "\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(encoder.vocab_size, 64),\n",
    "    #tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(train_dataset, epochs=10,\n",
    "                    validation_data=test_dataset, \n",
    "                    validation_steps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TypeScript",
   "language": "typescript",
   "name": "typescript"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}